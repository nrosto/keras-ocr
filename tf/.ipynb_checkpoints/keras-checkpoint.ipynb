{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550ee448-62ac-49d0-ab22-1329ca6b7d39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: opencv-python-headless 4.5.4.60\n",
      "Uninstalling opencv-python-headless-4.5.4.60:\n",
      "  Successfully uninstalled opencv-python-headless-4.5.4.60\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall opencv-python-headless --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223e80a2-d410-43c5-b3ed-72591b57f479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python==4.5.4.60\n",
      "  Downloading opencv_python-4.5.4.60-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.3 MB 12.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python==4.5.4.60) (1.23.2)\n",
      "Installing collected packages: opencv-python\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.10.0.84\n",
      "    Uninstalling opencv-python-4.10.0.84:\n",
      "      Successfully uninstalled opencv-python-4.10.0.84\n",
      "Successfully installed opencv-python-4.5.4.60\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python==4.5.4.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874c360e-a025-4e81-8925-553c02b308c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c9bb47-460a-4d3c-a4e1-a12e0da68782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc843b14-f907-4c25-a26e-6d26b2374dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'text'\n",
    "wordlist_file = os.path.join(data_dir, 'sah.wordlist')\n",
    "training_text_file = os.path.join(data_dir, 'sah.training_text')\n",
    "fonts_list_file = os.path.join(data_dir, 'okfonts_test.txt')\n",
    "\n",
    "fonts_dir = os.path.join(data_dir, 'fonts')\n",
    "\n",
    "output_dir = 'test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98c9309-e1ab-4a71-a453-e23d9c729475",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(wordlist_file, 'r', encoding='utf-8') as f:\n",
    "    words = f.readlines()\n",
    "\n",
    "with open(training_text_file, 'r', encoding='utf-8') as f:\n",
    "    training_text = f.readlines()\n",
    "\n",
    "with open(fonts_list_file, 'r', encoding='utf-8') as f:\n",
    "    styles = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce79c1db-38b3-4e19-b725-89e4005a073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fonts_from_styles(styles_list, base_fonts_dir):\n",
    "    fonts = []\n",
    "    for style in styles_list:\n",
    "        style_dir = os.path.join(base_fonts_dir, style)\n",
    "        if os.path.exists(style_dir):\n",
    "            for file in os.listdir(style_dir):\n",
    "                if file.endswith(('.ttf', '.otf')):\n",
    "                    fonts.append(os.path.join(style_dir, file))\n",
    "        else:\n",
    "            print(f\"Директория для стиля '{style}' не найдена: {style_dir}\")\n",
    "    return fonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00bd43fe-27e2-405c-8dd5-c4f9a68c2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts = load_fonts_from_styles(styles, fonts_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3419334-800a-44f6-a315-69cca5018caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(text, font_path, image_size=(500, 100), font_size=30):\n",
    "    image = Image.new('RGB', image_size, color=(255, 255, 255))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    try:\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "    except IOError:\n",
    "        print(f\"Не удалось загрузить шрифт: {font_path}\")\n",
    "        return None\n",
    "        \n",
    "    text_bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]\n",
    "    text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "    text_x = (image_size[0] - text_width) // 2\n",
    "    text_y = (image_size[1] - text_height) // 2\n",
    "\n",
    "    draw.text((text_x, text_y), text, font=font, fill=(0, 0, 0))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f57c21-9820-41bd-829f-99a1bb582e0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изображение сохранено: test_images/image_0_AlegreyaSans-ThinItalic.ttf.png\n",
      "Изображение сохранено: test_images/image_1_AlegreyaSans-ExtraBold.ttf.png\n",
      "Изображение сохранено: test_images/image_2_AlegreyaSans-MediumItalic.ttf.png\n",
      "Изображение сохранено: test_images/image_3_AlegreyaSans-Regular.ttf.png\n",
      "Изображение сохранено: test_images/image_4_AlegreyaSans-Light.ttf.png\n",
      "Изображение сохранено: test_images/image_5_AlegreyaSans-BlackItalic.ttf.png\n",
      "Изображение сохранено: test_images/image_6_AlegreyaSans-LightItalic.ttf.png\n",
      "Изображение сохранено: test_images/image_7_AlegreyaSans-Black.ttf.png\n",
      "Изображение сохранено: test_images/image_8_AlegreyaSans-BoldItalic.ttf.png\n",
      "Изображение сохранено: test_images/image_9_AlegreyaSans-Medium.ttf.png\n",
      "Изображение сохранено: test_images/image_10_AlegreyaSans-Bold.ttf.png\n",
      "Изображение сохранено: test_images/image_11_AlegreyaSans-Thin.ttf.png\n",
      "Изображение сохранено: test_images/image_12_AlegreyaSans-Italic.ttf.png\n",
      "Изображение сохранено: test_images/image_13_AlegreyaSans-ExtraBoldItalic.ttf.png\n",
      "Изображение сохранено: test_images/image_14_Alice-Regular.ttf.png\n",
      "Изображение сохранено: test_images/image_15_Arimo-Italic-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_16_Arimo-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_17_Bitter-Italic-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_18_Bitter-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_19_Comfortaa-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_20_Cormorant-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_21_Cormorant-Italic-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_22_EBGaramond-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_23_EBGaramond-Italic-VariableFont_wght.ttf.png\n",
      "Недостаточно шрифтов для всех текстов.\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(training_text):\n",
    "    if i < len(fonts):\n",
    "        font = fonts[i]\n",
    "        image = generate_image(text.strip(), font)\n",
    "        if image:\n",
    "            output_path = os.path.join(output_dir, f'image_{i}_{os.path.basename(font)}.png')\n",
    "            image.save(output_path)\n",
    "            print(f'Изображение сохранено: {output_path}')\n",
    "    else:\n",
    "        print(\"Недостаточно шрифтов для всех текстов.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3e03aad-6b3b-480b-b302-95f0242a14d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_ocr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b97e1e67-faa4-43cb-9129-b297a4f59dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /root/.keras-ocr/craft_mlt_25k.h5\n",
      "Downloading /root/.keras-ocr/craft_mlt_25k.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 23:18:34.051067: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-25 23:18:36.806020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13123 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-09-25 23:18:36.806901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 5288 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:24:00.0, compute capability: 8.6\n",
      "2024-09-25 23:18:36.807643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 16898 MB memory:  -> device: 2, name: NVIDIA RTX A5000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2024-09-25 23:18:36.808427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 16752 MB memory:  -> device: 3, name: NVIDIA RTX A5000, pci bus id: 0000:61:00.0, compute capability: 8.6\n",
      "2024-09-25 23:18:36.809086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 12821 MB memory:  -> device: 4, name: NVIDIA RTX A5000, pci bus id: 0000:a1:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /root/.keras-ocr/crnn_kurapan.h5\n",
      "Downloading /root/.keras-ocr/crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c39750-1f0e-4491-82c1-ee495f80b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames = [os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith('.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8298ccf1-26c6-4522-ba96-4b3cb8f014ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [keras_ocr.tools.read(image_filename) for image_filename in image_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68104d62-a775-434f-acef-2c7213b8f98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "5/5 [==============================] - 0s 69ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = pipeline.recognize(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6adc300c-7611-4f1b-93ca-beac53c7a840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text:\n",
      "t\n",
      "xopymayyp\n",
      "xaw\n",
      "cypyh\n",
      "biwbitbiblra\n",
      "awih\n",
      "Predicted text:\n",
      "cypyuaapbl\n",
      "kanaapu\n",
      "oyhyh\n",
      "tblmhblbl\n",
      "myo\n",
      "Predicted text:\n",
      "cblh\n",
      "enlehep\n",
      "copoxtopro\n",
      "cyplyk\n",
      "koncuups\n",
      "Predicted text:\n",
      "cblaaapbleap\n",
      "xaaaaah\n",
      "amucka\n",
      "yaaxahhbk\n",
      "s\n",
      "Predicted text:\n",
      "6\n",
      "abamap\n",
      "kuhu\n",
      "kahhummih\n",
      "uhhuha\n",
      "h\n",
      "kamueap\n",
      "Predicted text:\n",
      "myoha\n",
      "ohyhyh\n",
      "gueh\n",
      "aamn\n",
      "yh\n",
      "yy\n",
      "Predicted text:\n",
      "hblh\n",
      "obohyh\n",
      "obapblk\n",
      "buup\n",
      "caxa\n",
      "cypyh\n",
      "Predicted text:\n",
      "obaublblbl\n",
      "oe\n",
      "cypyh\n",
      "myoxmyp\n",
      "caha\n",
      "upima\n",
      "Predicted text:\n",
      "oho5y\n",
      "ycmama\n",
      "kemytyek\n",
      "kypaahax\n",
      "Predicted text:\n",
      "jbaakka\n",
      "zaat816\n",
      "slaapbl\n",
      "gjbimaapbl\n",
      "Predicted text:\n",
      "16at\n",
      "bblhah\n",
      "byonnar\n",
      "apbl\n",
      "xaibl\n",
      "aaybinap\n",
      "bl\n",
      "Predicted text:\n",
      "pdepep\n",
      "cblhblam\n",
      "caxa\n",
      "m\n",
      "mbiabieap\n",
      "mahhblk\n",
      "Predicted text:\n",
      "ymtah\n",
      "uhhvrep\n",
      "onnoohhooh\n",
      "oniopoh\n",
      "Predicted text:\n",
      "apkemmrapagtp\n",
      "gyonapxoo\n",
      "kehhmep\n",
      "Predicted text:\n",
      "cabbidblaablhah\n",
      "dush\n",
      "yeckeabum\n",
      "ca\n",
      "rku\n",
      "mbliablh\n",
      "Predicted text:\n",
      "bavifajitah\n",
      "xotyty\n",
      "myyctaax\n",
      "t\n",
      "kojior\n",
      "Predicted text:\n",
      "cblhblam\n",
      "myoxmyyp\n",
      "myc\n",
      "myoxmyyp\n",
      "pe\n",
      "k\n",
      "Predicted text:\n",
      "tyopaahbi\n",
      "hhbi\n",
      "tbimhbibihbl\n",
      "atahha\n",
      "Predicted text:\n",
      "d\n",
      "xaablibiba\n",
      "cblhblam\n",
      "omymmymyk\n",
      "myoxmyp\n",
      "Predicted text:\n",
      "cbihblattyoxtyp\n",
      "fah\n",
      "yeckyyp\n",
      "copohop\n",
      "cups\n",
      "Predicted text:\n",
      "ypytgah\n",
      "cblhbiat\n",
      "tyoxtyypi\n",
      "ypyt\n",
      "5\n",
      "c\n",
      "Predicted text:\n",
      "myoha\n",
      "tyhop\n",
      "eiaobya\n",
      "ivioh\n",
      "yecke\n",
      "h\n",
      "toctoh\n",
      "Predicted text:\n",
      "myoha\n",
      "occe\n",
      "rap\n",
      "ohyc\n",
      "yyhop\n",
      "ivioh\n",
      "atojjip\n",
      "Predicted text:\n",
      "muuueh\n",
      "oypeyymah\n",
      "h\n",
      "mblmhblblhan\n",
      "mblblhah\n"
     ]
    }
   ],
   "source": [
    "for image, prediction in zip(images, predictions):\n",
    "    print(\"Predicted text:\")\n",
    "    for word, box in prediction:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b2543c-837b-4e5d-8964-75f4a24fd031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras_ocr\n",
    "\n",
    "# keras-ocr will automatically download pretrained\n",
    "# weights for the detector and recognizer.\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# Get a set of three example images\n",
    "images = [\n",
    "    keras_ocr.tools.read(url) for url in [\n",
    "        'https://upload.wikimedia.org/wikipedia/commons/b/bd/Army_Reserves_Recruitment_Banner_MOD_45156284.jpg',\n",
    "        'https://upload.wikimedia.org/wikipedia/commons/b/b4/EUBanana-500x112.jpg'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892bcbcd-cf7b-450e-b53e-bfcceeecb836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each list of predictions in prediction_groups is a list of\n",
    "# (word, box) tuples.\n",
    "prediction_groups = pipeline.recognize(images)\n",
    "\n",
    "# Plot the predictions\n",
    "fig, axs = plt.subplots(nrows=len(images), figsize=(20, 20))\n",
    "for ax, image, predictions in zip(axs, images, prediction_groups):\n",
    "    keras_ocr.tools.drawAnnotations(image=image, predictions=predictions, ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
