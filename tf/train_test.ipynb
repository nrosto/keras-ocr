{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36176928-9257-4c28-ab19-189b9c1b84dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import keras_ocr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba1c0caa-cf49-4092-accc-bb09138e7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройка алфавита для якутского языка\n",
    "alphabet = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюяҕҥөһү '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc46ed90-cd87-4f5f-93f7-2af6e53fe0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided alphabet does not match pretrained alphabet. Using backbone weights only.\n",
      "Looking for /root/.keras-ocr/crnn_kurapan_notop.h5\n"
     ]
    }
   ],
   "source": [
    "recognizer = keras_ocr.recognition.Recognizer(alphabet=alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb14f09a-c782-4120-861c-7279cf1621d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к файлу с аннотациями\n",
    "annotations_file = 'images/annotations.json'\n",
    "\n",
    "# Загрузка аннотаций из файла\n",
    "with open(annotations_file, 'r', encoding='utf-8') as f:\n",
    "    annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c3e0167a-c994-48ba-9b60-a7a51bd25af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для подготовки данных с использованием bounding boxes\n",
    "def prepare_data_with_boxes(annotations):\n",
    "    images = []\n",
    "    texts = []\n",
    "    for annotation in annotations:\n",
    "        image_path = annotation['image']\n",
    "        text = annotation['text']\n",
    "        bbox = annotation.get('bbox', None)\n",
    "        \n",
    "        if bbox is not None:\n",
    "            # Преобразуем bbox в формат, ожидаемый Keras-OCR\n",
    "            x1, y1 = bbox[0]\n",
    "            x2, y2 = bbox[1]\n",
    "            box = np.array([\n",
    "                [x1, y1],  # Верхний левый\n",
    "                [x2, y1],  # Верхний правый\n",
    "                [x2, y2],  # Нижний правый\n",
    "                [x1, y2]   # Нижний левый\n",
    "            ], dtype=np.float32)\n",
    "        else:\n",
    "            box = None\n",
    "        \n",
    "        img = keras_ocr.tools.read(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Не удалось загрузить изображение: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        if box is not None:\n",
    "            cropped_img = keras_ocr.tools.warpBox(\n",
    "                image=img,\n",
    "                box=box,\n",
    "                target_height=recognizer.model.input_shape[1],\n",
    "                target_width=recognizer.model.input_shape[2]\n",
    "            )\n",
    "            images.append(cropped_img)\n",
    "        else:\n",
    "            images.append(img)\n",
    "        texts.append(text)\n",
    "    return images, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d21b34c8-ff92-46dd-8884-db5d90e552e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, texts = prepare_data_with_boxes(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9d20456-a146-4c2d-a14b-acdc020a5b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на обучающую и тестовую выборки\n",
    "split_index = int(len(images) * 0.8)\n",
    "train_images = images[:split_index]\n",
    "train_texts = texts[:split_index]\n",
    "test_images = images[split_index:]\n",
    "test_texts = texts[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4bdaea0c-3fde-4879-a8e5-9e6847ffd74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infinite_image_generator(images, texts):\n",
    "    while True:\n",
    "        for img, txt in zip(images, texts):\n",
    "            yield img, txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "11f85a62-3422-49b8-bb5e-3322f1bdcf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_gen = infinite_image_generator(train_images, train_texts)\n",
    "validation_image_gen = infinite_image_generator(test_images, test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd9c744b-5fde-4edd-8f4c-92343c32b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "height = recognizer.model.input_shape[1]\n",
    "width = recognizer.model.input_shape[2]\n",
    "\n",
    "# Создание генераторов данных для обучения\n",
    "train_gen = recognizer.get_batch_generator(\n",
    "    image_generator=train_image_gen,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "validation_gen = recognizer.get_batch_generator(\n",
    "    image_generator=validation_image_gen,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d46fd787-32b4-4e52-919a-423cd3469172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "train_steps = math.ceil(len(train_images) / batch_size)\n",
    "validation_steps = math.ceil(len(test_images) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce6158ae-0873-47a8-9e20-e830fa02b1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_loss(y_true, y_pred):\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b92c502-0283-4388-88ce-e1e3461320cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer.training_model.compile(optimizer='adam', loss=dummy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5de3d4fa-e9df-4998-9f37-21cbdd1d2e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 12s 61ms/step - loss: 22.3668 - val_loss: 24.0258\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 22.1043 - val_loss: 24.7740\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 22.6058 - val_loss: 26.7154\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 22.5306 - val_loss: 25.0138\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 23.1938 - val_loss: 25.3423\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 21.9441 - val_loss: 24.3439\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 22.0388 - val_loss: 24.0094\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 21.9510 - val_loss: 24.5944\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 20.9572 - val_loss: 25.0414\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 21.1378 - val_loss: 25.4869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f463c52f910>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучение распознавателя\n",
    "recognizer.training_model.fit(\n",
    "    train_gen,\n",
    "    validation_data=validation_gen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e2ca2-b70e-46fe-ad0b-9521658ca04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
