{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550ee448-62ac-49d0-ab22-1329ca6b7d39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: opencv-python-headless 4.10.0.84\n",
      "Uninstalling opencv-python-headless-4.10.0.84:\n",
      "  Successfully uninstalled opencv-python-headless-4.10.0.84\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall opencv-python-headless --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "223e80a2-d410-43c5-b3ed-72591b57f479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python==4.5.4.60\n",
      "  Using cached opencv-python-4.5.4.60.tar.gz (89.8 MB)\n",
      "  Installing build dependencies ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[22 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version == \"3.6\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version == \"3.7\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version == \"3.8\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version <= \"3.9\" and sys_platform == \"linux\" and platform_machine == \"aarch64\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version <= \"3.9\" and sys_platform == \"darwin\" and platform_machine == \"arm64\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version == \"3.9\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Collecting setuptools\n",
      "  \u001b[31m   \u001b[0m   Using cached setuptools-75.1.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting wheel\n",
      "  \u001b[31m   \u001b[0m   Using cached wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting scikit-build\n",
      "  \u001b[31m   \u001b[0m   Using cached scikit_build-0.18.1-py3-none-any.whl.metadata (18 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting cmake\n",
      "  \u001b[31m   \u001b[0m   Using cached cmake-3.30.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting pip\n",
      "  \u001b[31m   \u001b[0m   Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "  \u001b[31m   \u001b[0m \u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\u001b[0m\u001b[31m\n",
      "  \u001b[31m   \u001b[0m \u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement numpy==1.21.2 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4, 1.25.0, 1.25.1, 1.25.2, 1.26.0, 1.26.1, 1.26.2, 1.26.3, 1.26.4, 2.0.0, 2.0.1, 2.0.2, 2.1.0rc1, 2.1.0, 2.1.1)\u001b[0m\u001b[31m\n",
      "  \u001b[31m   \u001b[0m \u001b[0m\u001b[31mERROR: No matching distribution found for numpy==1.21.2\u001b[0m\u001b[31m\n",
      "  \u001b[31m   \u001b[0m \u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python==4.5.4.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "874c360e-a025-4e81-8925-553c02b308c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c9bb47-460a-4d3c-a4e1-a12e0da68782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc843b14-f907-4c25-a26e-6d26b2374dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'text'\n",
    "wordlist_file = os.path.join(data_dir, 'sah.wordlist')\n",
    "training_text_file = os.path.join(data_dir, 'sah.training_text')\n",
    "fonts_list_file = os.path.join(data_dir, 'okfonts_test.txt')\n",
    "\n",
    "fonts_dir = os.path.join(data_dir, 'fonts')\n",
    "\n",
    "output_dir = 'test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98c9309-e1ab-4a71-a453-e23d9c729475",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(wordlist_file, 'r', encoding='utf-8') as f:\n",
    "    words = f.readlines()\n",
    "\n",
    "with open(training_text_file, 'r', encoding='utf-8') as f:\n",
    "    training_text = f.readlines()\n",
    "\n",
    "with open(fonts_list_file, 'r', encoding='utf-8') as f:\n",
    "    styles = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce79c1db-38b3-4e19-b725-89e4005a073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fonts_from_styles(styles_list, base_fonts_dir):\n",
    "    fonts = []\n",
    "    for style in styles_list:\n",
    "        style_dir = os.path.join(base_fonts_dir, style)\n",
    "        if os.path.exists(style_dir):\n",
    "            for file in os.listdir(style_dir):\n",
    "                if file.endswith(('.ttf', '.otf')):\n",
    "                    fonts.append(os.path.join(style_dir, file))\n",
    "        else:\n",
    "            print(f\"Директория для стиля '{style}' не найдена: {style_dir}\")\n",
    "    return fonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00bd43fe-27e2-405c-8dd5-c4f9a68c2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts = load_fonts_from_styles(styles, fonts_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3419334-800a-44f6-a315-69cca5018caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(text, font_path, image_size=(500, 100), font_size=30):\n",
    "    image = Image.new('RGB', image_size, color=(255, 255, 255))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    try:\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "    except IOError:\n",
    "        print(f\"Не удалось загрузить шрифт: {font_path}\")\n",
    "        return None\n",
    "        \n",
    "    text_bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]\n",
    "    text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "    text_x = (image_size[0] - text_width) // 2\n",
    "    text_y = (image_size[1] - text_height) // 2\n",
    "\n",
    "    draw.text((text_x, text_y), text, font=font, fill=(0, 0, 0))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f57c21-9820-41bd-829f-99a1bb582e0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изображение сохранено: test_images/image_0_AlegreyaSans-ThinItalic.ttf.png\n",
      "Изображение сохранено: test_images/image_1_AlegreyaSans-ExtraBold.ttf.png\n",
      "Изображение сохранено: test_images/image_2_AlegreyaSans-MediumItalic.ttf.png\n",
      "Изображение сохранено: test_images/image_3_AlegreyaSans-Regular.ttf.png\n",
      "Изображение сохранено: test_images/image_4_AlegreyaSans-Light.ttf.png\n",
      "Изображение сохранено: test_images/image_5_AlegreyaSans-BlackItalic.ttf.png\n",
      "Изображение сохранено: test_images/image_6_AlegreyaSans-LightItalic.ttf.png\n",
      "Изображение сохранено: test_images/image_7_AlegreyaSans-Black.ttf.png\n",
      "Изображение сохранено: test_images/image_8_AlegreyaSans-BoldItalic.ttf.png\n",
      "Изображение сохранено: test_images/image_9_AlegreyaSans-Medium.ttf.png\n",
      "Изображение сохранено: test_images/image_10_AlegreyaSans-Bold.ttf.png\n",
      "Изображение сохранено: test_images/image_11_AlegreyaSans-Thin.ttf.png\n",
      "Изображение сохранено: test_images/image_12_AlegreyaSans-Italic.ttf.png\n",
      "Изображение сохранено: test_images/image_13_AlegreyaSans-ExtraBoldItalic.ttf.png\n",
      "Изображение сохранено: test_images/image_14_Alice-Regular.ttf.png\n",
      "Изображение сохранено: test_images/image_15_Arimo-Italic-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_16_Arimo-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_17_Bitter-Italic-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_18_Bitter-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_19_Comfortaa-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_20_Cormorant-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_21_Cormorant-Italic-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_22_EBGaramond-VariableFont_wght.ttf.png\n",
      "Изображение сохранено: test_images/image_23_EBGaramond-Italic-VariableFont_wght.ttf.png\n",
      "Недостаточно шрифтов для всех текстов.\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(training_text):\n",
    "    if i < len(fonts):\n",
    "        font = fonts[i]\n",
    "        image = generate_image(text.strip(), font)\n",
    "        if image:\n",
    "            output_path = os.path.join(output_dir, f'image_{i}_{os.path.basename(font)}.png')\n",
    "            image.save(output_path)\n",
    "            print(f'Изображение сохранено: {output_path}')\n",
    "    else:\n",
    "        print(\"Недостаточно шрифтов для всех текстов.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3e03aad-6b3b-480b-b302-95f0242a14d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_ocr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b97e1e67-faa4-43cb-9129-b297a4f59dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /root/.keras-ocr/craft_mlt_25k.h5\n",
      "Downloading /root/.keras-ocr/craft_mlt_25k.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 23:18:34.051067: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-25 23:18:36.806020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13123 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-09-25 23:18:36.806901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 5288 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:24:00.0, compute capability: 8.6\n",
      "2024-09-25 23:18:36.807643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 16898 MB memory:  -> device: 2, name: NVIDIA RTX A5000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2024-09-25 23:18:36.808427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 16752 MB memory:  -> device: 3, name: NVIDIA RTX A5000, pci bus id: 0000:61:00.0, compute capability: 8.6\n",
      "2024-09-25 23:18:36.809086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 12821 MB memory:  -> device: 4, name: NVIDIA RTX A5000, pci bus id: 0000:a1:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /root/.keras-ocr/crnn_kurapan.h5\n",
      "Downloading /root/.keras-ocr/crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c39750-1f0e-4491-82c1-ee495f80b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames = [os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith('.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8298ccf1-26c6-4522-ba96-4b3cb8f014ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [keras_ocr.tools.read(image_filename) for image_filename in image_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68104d62-a775-434f-acef-2c7213b8f98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "5/5 [==============================] - 0s 69ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = pipeline.recognize(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6adc300c-7611-4f1b-93ca-beac53c7a840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text:\n",
      "t\n",
      "xopymayyp\n",
      "xaw\n",
      "cypyh\n",
      "biwbitbiblra\n",
      "awih\n",
      "Predicted text:\n",
      "cypyuaapbl\n",
      "kanaapu\n",
      "oyhyh\n",
      "tblmhblbl\n",
      "myo\n",
      "Predicted text:\n",
      "cblh\n",
      "enlehep\n",
      "copoxtopro\n",
      "cyplyk\n",
      "koncuups\n",
      "Predicted text:\n",
      "cblaaapbleap\n",
      "xaaaaah\n",
      "amucka\n",
      "yaaxahhbk\n",
      "s\n",
      "Predicted text:\n",
      "6\n",
      "abamap\n",
      "kuhu\n",
      "kahhummih\n",
      "uhhuha\n",
      "h\n",
      "kamueap\n",
      "Predicted text:\n",
      "myoha\n",
      "ohyhyh\n",
      "gueh\n",
      "aamn\n",
      "yh\n",
      "yy\n",
      "Predicted text:\n",
      "hblh\n",
      "obohyh\n",
      "obapblk\n",
      "buup\n",
      "caxa\n",
      "cypyh\n",
      "Predicted text:\n",
      "obaublblbl\n",
      "oe\n",
      "cypyh\n",
      "myoxmyp\n",
      "caha\n",
      "upima\n",
      "Predicted text:\n",
      "oho5y\n",
      "ycmama\n",
      "kemytyek\n",
      "kypaahax\n",
      "Predicted text:\n",
      "jbaakka\n",
      "zaat816\n",
      "slaapbl\n",
      "gjbimaapbl\n",
      "Predicted text:\n",
      "16at\n",
      "bblhah\n",
      "byonnar\n",
      "apbl\n",
      "xaibl\n",
      "aaybinap\n",
      "bl\n",
      "Predicted text:\n",
      "pdepep\n",
      "cblhblam\n",
      "caxa\n",
      "m\n",
      "mbiabieap\n",
      "mahhblk\n",
      "Predicted text:\n",
      "ymtah\n",
      "uhhvrep\n",
      "onnoohhooh\n",
      "oniopoh\n",
      "Predicted text:\n",
      "apkemmrapagtp\n",
      "gyonapxoo\n",
      "kehhmep\n",
      "Predicted text:\n",
      "cabbidblaablhah\n",
      "dush\n",
      "yeckeabum\n",
      "ca\n",
      "rku\n",
      "mbliablh\n",
      "Predicted text:\n",
      "bavifajitah\n",
      "xotyty\n",
      "myyctaax\n",
      "t\n",
      "kojior\n",
      "Predicted text:\n",
      "cblhblam\n",
      "myoxmyyp\n",
      "myc\n",
      "myoxmyyp\n",
      "pe\n",
      "k\n",
      "Predicted text:\n",
      "tyopaahbi\n",
      "hhbi\n",
      "tbimhbibihbl\n",
      "atahha\n",
      "Predicted text:\n",
      "d\n",
      "xaablibiba\n",
      "cblhblam\n",
      "omymmymyk\n",
      "myoxmyp\n",
      "Predicted text:\n",
      "cbihblattyoxtyp\n",
      "fah\n",
      "yeckyyp\n",
      "copohop\n",
      "cups\n",
      "Predicted text:\n",
      "ypytgah\n",
      "cblhbiat\n",
      "tyoxtyypi\n",
      "ypyt\n",
      "5\n",
      "c\n",
      "Predicted text:\n",
      "myoha\n",
      "tyhop\n",
      "eiaobya\n",
      "ivioh\n",
      "yecke\n",
      "h\n",
      "toctoh\n",
      "Predicted text:\n",
      "myoha\n",
      "occe\n",
      "rap\n",
      "ohyc\n",
      "yyhop\n",
      "ivioh\n",
      "atojjip\n",
      "Predicted text:\n",
      "muuueh\n",
      "oypeyymah\n",
      "h\n",
      "mblmhblblhan\n",
      "mblblhah\n"
     ]
    }
   ],
   "source": [
    "for image, prediction in zip(images, predictions):\n",
    "    print(\"Predicted text:\")\n",
    "    for word, box in prediction:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b2543c-837b-4e5d-8964-75f4a24fd031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /root/.keras-ocr/craft_mlt_25k.h5\n",
      "Downloading /root/.keras-ocr/craft_mlt_25k.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 03:41:30.444418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19678 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-09-27 03:41:30.445274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 17026 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:24:00.0, compute capability: 8.6\n",
      "2024-09-27 03:41:30.445883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 5592 MB memory:  -> device: 2, name: NVIDIA RTX A5000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2024-09-27 03:41:30.446475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22501 MB memory:  -> device: 3, name: NVIDIA RTX A5000, pci bus id: 0000:61:00.0, compute capability: 8.6\n",
      "2024-09-27 03:41:30.447065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 13097 MB memory:  -> device: 4, name: NVIDIA RTX A5000, pci bus id: 0000:a1:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments passed to Dense: {'weights': [array([[0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([1., 0., 0., 0., 1., 0.], dtype=float32)]}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras_ocr\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# keras-ocr will automatically download pretrained\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# weights for the detector and recognizer.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mkeras_ocr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get a set of three example images\u001b[39;00m\n\u001b[1;32m     10\u001b[0m images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     keras_ocr\u001b[38;5;241m.\u001b[39mtools\u001b[38;5;241m.\u001b[39mread(url) \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://upload.wikimedia.org/wikipedia/commons/b/bd/Army_Reserves_Recruitment_Banner_MOD_45156284.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://upload.wikimedia.org/wikipedia/commons/b/b4/EUBanana-500x112.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m     ]\n\u001b[1;32m     15\u001b[0m ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_ocr/pipeline.py:22\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[0;34m(self, detector, recognizer, scale, max_size)\u001b[0m\n\u001b[1;32m     20\u001b[0m     detector \u001b[38;5;241m=\u001b[39m detection\u001b[38;5;241m.\u001b[39mDetector()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recognizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     recognizer \u001b[38;5;241m=\u001b[39m \u001b[43mrecognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecognizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m scale\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector \u001b[38;5;241m=\u001b[39m detector\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_ocr/recognition.py:388\u001b[0m, in \u001b[0;36mRecognizer.__init__\u001b[0;34m(self, alphabet, weights, build_params)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphabet \u001b[38;5;241m=\u001b[39m alphabet\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblank_label_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(alphabet)\n\u001b[1;32m    383\u001b[0m (\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_model,\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_model,\n\u001b[0;32m--> 388\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbuild_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m     weights_dict \u001b[38;5;241m=\u001b[39m PRETRAINED_WEIGHTS[weights]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_ocr/recognition.py:277\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(alphabet, height, width, color, filters, rnn_units, dropout, rnn_steps_to_discard, pool_size, stn)\u001b[0m\n\u001b[1;32m    275\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten()(locnet_y)\n\u001b[1;32m    276\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)(locnet_y)\n\u001b[0;32m--> 277\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m(locnet_y)\n\u001b[1;32m    284\u001b[0m localization_net \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39mstn_input_layer, outputs\u001b[38;5;241m=\u001b[39mlocnet_y)\n\u001b[1;32m    285\u001b[0m x \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(_transform, output_shape\u001b[38;5;241m=\u001b[39mstn_input_output_shape)(\n\u001b[1;32m    286\u001b[0m     [x, localization_net(x)]\n\u001b[1;32m    287\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87\u001b[0m, in \u001b[0;36mDense.__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, lora_rank, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     74\u001b[0m     units,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     86\u001b[0m ):\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mactivity_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivity_regularizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m units\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m activations\u001b[38;5;241m.\u001b[39mget(activation)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:266\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m     )\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Will be determined in `build_wrapper`\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Dense: {'weights': [array([[0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([1., 0., 0., 0., 1., 0.], dtype=float32)]}"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras_ocr\n",
    "\n",
    "# keras-ocr will automatically download pretrained\n",
    "# weights for the detector and recognizer.\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# Get a set of three example images\n",
    "images = [\n",
    "    keras_ocr.tools.read(url) for url in [\n",
    "        'https://upload.wikimedia.org/wikipedia/commons/b/bd/Army_Reserves_Recruitment_Banner_MOD_45156284.jpg',\n",
    "        'https://upload.wikimedia.org/wikipedia/commons/b/b4/EUBanana-500x112.jpg'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892bcbcd-cf7b-450e-b53e-bfcceeecb836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each list of predictions in prediction_groups is a list of\n",
    "# (word, box) tuples.\n",
    "prediction_groups = pipeline.recognize(images)\n",
    "\n",
    "# Plot the predictions\n",
    "fig, axs = plt.subplots(nrows=len(images), figsize=(20, 20))\n",
    "for ax, image, predictions in zip(axs, images, prediction_groups):\n",
    "    keras_ocr.tools.drawAnnotations(image=image, predictions=predictions, ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
