{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1060b1-5636-4d84-a02e-fe33e467b3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72fbd2b3-e635-4701-a542-cac39282647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ec2a350-fa50-4892-8dc5-1e2a98aeb181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к файлу с аннотациями\n",
    "annotations_file = 'images/annotations.json'\n",
    "\n",
    "# Загрузка аннотаций из файла\n",
    "with open(annotations_file, 'r', encoding='utf-8') as f:\n",
    "    annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a205afed-9c80-49a7-b989-47bd036859d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для отображения изображения с bounding box\n",
    "def display_image_with_box(annotation):\n",
    "    # Загрузка изображения\n",
    "    image_path = annotation['image']\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Не удалось загрузить изображение: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Получение bounding box\n",
    "    bbox = annotation.get('bbox', None)\n",
    "    \n",
    "    if bbox is not None:\n",
    "        x1, y1 = bbox[0]  # Верхний левый угол\n",
    "        x2, y2 = bbox[1] # Нижний правый угол\n",
    "        y2 += 15\n",
    "        \n",
    "        # Отрисовываем прямоугольник на изображении\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
    "    \n",
    "    # Преобразуем изображение в RGB для корректного отображения в Matplotlib\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Отображаем изображение\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')  # Отключаем оси\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f35a48ff-ce18-4624-8e09-05850f710774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image_with_box(annotations[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60d2276e-f290-4b1e-8e6e-6867e440fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание списков путей к изображениям и текстов\n",
    "image_paths = []\n",
    "texts = []\n",
    "\n",
    "for annotation in annotations:\n",
    "    img_path = annotation['image']\n",
    "    text = annotation['text']\n",
    "    \n",
    "    if os.path.exists(img_path):\n",
    "        image_paths.append(img_path)\n",
    "        texts.append(text)\n",
    "    else:\n",
    "        print(f\"Изображение не найдено: {img_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c33fe4c-6a9b-4c6e-b5f8-60772cc2bb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 800, Validation: 100, Test: 100\n"
     ]
    }
   ],
   "source": [
    "train_images, temp_images, train_texts, temp_texts = train_test_split(\n",
    "    image_paths, texts, test_size=0.2, random_state=42)\n",
    "\n",
    "val_images, test_images, val_texts, test_texts = train_test_split(\n",
    "    temp_images, temp_texts, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_images)}, Validation: {len(val_images)}, Test: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29b18edb-cec7-4c20-aa08-f632d9dfd93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение набора символов\n",
    "characters = string.ascii_letters + string.digits + 'абвгдеёжзийклмнопрстуфхцчшщъыьэюяҕҥөһүАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯҔҤӨҺҮ '\n",
    "\n",
    "# Создание маппинга\n",
    "char_to_num = {char: idx + 1 for idx, char in enumerate(characters)}  # 0 будет использоваться для CTC blank\n",
    "num_to_char = {idx + 1: char for idx, char in enumerate(characters)}\n",
    "\n",
    "def text_to_labels(text):\n",
    "    return [char_to_num[char] for char in text if char in char_to_num]\n",
    "\n",
    "def labels_to_text(labels):\n",
    "    return ''.join([num_to_char[label] for label in labels if label in num_to_char])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f4a3e96-c779-4610-9867-4d31b3c5a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, img_height, img_width):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Не удалось загрузить изображение: {image_path}\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (img_width, img_height))\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255.0  # Нормализация\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65fb6941-e808-411e-b5a7-ab0068852931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 256\n",
    "BATCH_SIZE = 32\n",
    "MAX_LABEL_LENGTH = 20  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5082d22a-8942-4656-853b-45f75ab6b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодирование примера\n",
    "def encode_sample(image_path, text):\n",
    "    img = preprocess_image(image_path, IMG_HEIGHT, IMG_WIDTH)\n",
    "    label = text_to_labels(text)\n",
    "    return img, label\n",
    "\n",
    "# Обёртка для TensorFlow\n",
    "def tf_encode(image_path, text):\n",
    "    img, label = tf.py_function(func=encode_sample, inp=[image_path, text], Tout=[tf.float32, tf.int32])\n",
    "    img.set_shape([IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "    label.set_shape([None])\n",
    "    return img, label\n",
    "\n",
    "# Создание TensorFlow Dataset\n",
    "def prepare_dataset(images, texts):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, texts))\n",
    "    dataset = dataset.map(tf_encode, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b11a82d8-0986-4179-a909-10e88dd7f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = prepare_dataset(train_images, train_texts)\n",
    "val_dataset = prepare_dataset(val_images, val_texts)\n",
    "test_dataset = prepare_dataset(test_images, test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0150ef6d-1c9e-47af-8329-28b162c79783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(batch):\n",
    "    images, labels = batch\n",
    "    labels = pad_sequences(labels, maxlen=MAX_LABEL_LENGTH, padding='post', value=0)\n",
    "    label_length = tf.math.count_nonzero(labels, axis=1)\n",
    "    input_length = tf.ones(tf.shape(labels)[0]) * (IMG_WIDTH // 4)  # Примерное значение, зависит от модели\n",
    "    return {\n",
    "        \"input_image\": images,\n",
    "        \"labels\": labels,\n",
    "        \"input_length\": input_length,\n",
    "        \"label_length\": label_length\n",
    "    }, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54e2f5d0-5562-4bec-9823-a9ec52c359f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__prepare_batch() takes 1 positional argument but 2 were given\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepare_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m      2\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m val_dataset\u001b[38;5;241m.\u001b[39mbatch(BATCH_SIZE)\u001b[38;5;241m.\u001b[39mmap(prepare_batch)\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m      3\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mbatch(BATCH_SIZE)\u001b[38;5;241m.\u001b[39mmap(prepare_batch)\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/dataset_ops.py:2311\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2307\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2308\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2309\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2310\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2312\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    113\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1251\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1250\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1251\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1221\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1220\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1225\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    694\u001b[0m )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__prepare_batch() takes 1 positional argument but 2 were given\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.batch(BATCH_SIZE).map(prepare_batch).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).map(prepare_batch).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).map(prepare_batch).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7e76d76-50b8-4856-82e8-6ba4eafa7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка и предобработка изображений\n",
    "def load_and_preprocess_image(image_path, img_height, img_width):\n",
    "    image = load_img(image_path, target_size=(img_height, img_width))\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)  # Специфичная для ResNet предобработка\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfaa7f83-4a4e-4019-98ef-d78e1a64bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 224, 224  # Размеры входных данных для ResNet\n",
    "images = [load_and_preprocess_image(ann['image'], img_height, img_width) for ann in annotations]\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d1a065f-6ced-42bb-ad06-e69653b9b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодирование меток для CTC Loss\n",
    "char_list = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюяҕҥөһү ' + '-'  # Добавляем символ CTC blank\n",
    "num_classes = len(char_list) + 1  # Количество классов + 1 для CTC blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "017626e0-0ba2-43c9-bef7-7c3e3dd12120",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_labels = {char: idx for idx, char in enumerate(char_list)}\n",
    "labels = [[char_to_labels[char] for char in ann['text']] for ann in annotations]\n",
    "\n",
    "# Паддинг меток\n",
    "max_label_len = max(len(label) for label in labels)\n",
    "labels_padded = tf.keras.preprocessing.sequence.pad_sequences(labels, maxlen=max_label_len, padding='post', value=num_classes-1)\n",
    "\n",
    "# Создание массивов input_length и label_length\n",
    "input_length = np.full((len(images), 1), img_width // 32 * img_height // 32 - 2)  # Оценка длины последовательности после CNN\n",
    "label_length = np.array([[len(label)] for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abef171a-ab26-433f-8fb4-ce95ad3a928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Reshape, Bidirectional, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56eec518-4982-4381-b131-48833cda8ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение модели\n",
    "def build_model():\n",
    "    input_img = Input(shape=(img_height, img_width, 3), name='image_input')\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_img)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False  # Замораживаем веса ResNet\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Reshape(target_shape=(-1, 2048))(x)\n",
    "    x = Bidirectional(LSTM(256, return_sequences=True, dropout=0.2))(x)\n",
    "    output = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "\n",
    "    labels = Input(name='labels', shape=[max_label_len], dtype='int64')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    def ctc_lambda_func(args):\n",
    "        y_pred, labels, input_length, label_length = args\n",
    "        return tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "    loss_out = tf.keras.layers.Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([output, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input_img, labels, input_length, label_length], outputs=loss_out)\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.compile(optimizer='adam', loss={'ctc': lambda y_true, y_pred: y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4371d651-a56e-4864-9b0a-a76d49b92407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "    'image_input': images, \n",
    "    'labels': labels_padded, \n",
    "    'input_length': input_length, \n",
    "    'label_length': label_length\n",
    "    }, np.zeros(len(images)))).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6f04e14-0684-4f81-9993-c8751f2da996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 7s 33ms/step - loss: 30.5711\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 23.2354\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 22.6501\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 22.1890\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 21.7094\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 21.2569\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 20.8315\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 20.3403\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 19.9711\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 19.5223\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 19.0524\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 18.5467\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 18.0775\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 17.6242\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 17.1121\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 16.5765\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 16.0968\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 15.7006\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 15.2835\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 14.6833\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 14.0834\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 13.4830\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 12.9706\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 12.4496\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 12.0063\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 11.5860\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 11.2804\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 10.7214\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 10.3539\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 9.9157\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 9.3307\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 8.9144\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 8.6215\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 8.1790\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 7.9231\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 7.4889\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 7.2577\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 6.6355\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 6.2288\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 5.7249\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 5.5348\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 5.3192\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 5.1737\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 4.8279\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 4.6249\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 4.4714\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 4.3155\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 4.1461\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 3.8273\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 3.7295\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d05a454-b207-477d-adb7-0c0ee801e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, img_height, img_width):\n",
    "    # Загрузка изображения, изменение размера и предварительная обработка\n",
    "    image = load_img(image_path, target_size=(img_height, img_width))\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)  # Применяем ту же предобработку, что и для обучения\n",
    "    image = np.expand_dims(image, axis=0)  # Расширяем размеры для сети\n",
    "    return image\n",
    "\n",
    "# Предполагается, что у вас есть путь к изображению\n",
    "image_path = 'images/а5атын.png'\n",
    "image = preprocess_image(image_path, img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9b7000f-d6d8-4eff-bdb4-ad98b291b362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание подмодели для предсказания\n",
    "predict_model = Model(inputs=model.get_layer(name='image_input').input,\n",
    "                      outputs=model.get_layer(name='output').output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50367f74-9bff-480a-8a80-f01d8b7e1d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка изображения\n",
    "def preprocess_image(image_path, img_height, img_width):\n",
    "    image = load_img(image_path, target_size=(img_height, img_width))\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "    image = np.expand_dims(image, axis=0)  # Добавляем batch размерность\n",
    "    return image\n",
    "\n",
    "image_path = 'images/а5атын.png'\n",
    "image = preprocess_image(image_path, img_height, img_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d0c0e74-8576-4b8f-99f3-ab0b1d887ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "preds = predict_model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8c2aab6-e73c-4c13-96ce-f713894bc84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распознанный текст: към\n"
     ]
    }
   ],
   "source": [
    "char_list = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюяҕҥөһү '\n",
    "\n",
    "# Функция для декодирования выхода из модели\n",
    "def decode_predict_ctc(out):\n",
    "    input_len = np.ones(out.shape[0]) * out.shape[1]\n",
    "    decoded, _ = tf.keras.backend.ctc_decode(out, input_length=input_len, greedy=True)\n",
    "    decoded = tf.keras.backend.get_value(decoded[0])\n",
    "\n",
    "    # Преобразование из индексов в символы, игнорируя CTC blank (0) и -1\n",
    "    pred_text = ''.join([num_to_char[x] for x in decoded[0] if x != -1 and x != 0])\n",
    "    return pred_text\n",
    "\n",
    "# Декодирование предсказаний в текст\n",
    "predicted_text = decode_predict_ctc(preds)\n",
    "print(\"Распознанный текст:\", predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265041bc-c81b-4d0f-a693-db30862e5dee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
