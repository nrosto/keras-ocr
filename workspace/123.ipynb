{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "329d73f8-b280-4de0-978d-6f66fa2c19fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af1c3984-ba2c-4ec2-ae00-67a50b8a32b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fa3084a-010f-4a2b-81af-b9f5067f2f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data_folder = 'generated_data'\n",
    "train_src_folder = os.path.join(generated_data_folder, 'sah_filtered')\n",
    "val_src_folder = os.path.join(generated_data_folder, 'val')\n",
    "train_labels_file = os.path.join(train_src_folder, 'labels.csv')\n",
    "val_labels_file = os.path.join(val_src_folder, 'labels.csv')\n",
    "\n",
    "target_data_folder = 'data/sah'\n",
    "train_target_images = os.path.join(target_data_folder, 'train', 'images')\n",
    "train_target_labels = os.path.join(target_data_folder, 'train', 'labels')\n",
    "val_target_images = os.path.join(target_data_folder, 'val', 'images')\n",
    "val_target_labels = os.path.join(target_data_folder, 'val', 'labels')\n",
    "\n",
    "os.makedirs(train_target_images, exist_ok=True)\n",
    "os.makedirs(train_target_labels, exist_ok=True)\n",
    "os.makedirs(val_target_images, exist_ok=True)\n",
    "os.makedirs(val_target_labels, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c1bac25-7621-42a4-887c-f6d8da64fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_split(src_images_folder, src_labels_file, target_images_folder, target_labels_folder):\n",
    "    df = pd.read_csv(src_labels_file)\n",
    "    \n",
    "    df['filename'] = df['filename'].apply(lambda x: os.path.join('images', x))\n",
    "    \n",
    "    target_labels_file = os.path.join(target_labels_folder, 'labels.csv')\n",
    "    df.to_csv(target_labels_file, index=False, encoding='utf-8')\n",
    "    print(f\"Файл меток сохранён: {target_labels_file}\")\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        src_img_path = os.path.join(src_images_folder, row['filename'].split('images/')[1])\n",
    "        target_img_path = os.path.join(target_images_folder, row['filename'].split('images/')[1])\n",
    "        if not os.path.exists(src_img_path):\n",
    "            print(f\"Изображение не найдено: {src_img_path}\")\n",
    "            continue\n",
    "        shutil.copy(src_img_path, target_img_path)\n",
    "        if (idx + 1) % 1000 == 0:\n",
    "            print(f\"Скопировано {idx + 1} изображений...\")\n",
    "    \n",
    "    print(f\"Копирование изображений из {src_images_folder} завершено.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a46b79df-d223-4706-8cc3-a1cfc95a2184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл меток сохранён: data/sah/train/labels/labels.csv\n",
      "Скопировано 1000 изображений...\n",
      "Скопировано 2000 изображений...\n",
      "Скопировано 3000 изображений...\n",
      "Скопировано 4000 изображений...\n",
      "Скопировано 5000 изображений...\n",
      "Скопировано 6000 изображений...\n",
      "Скопировано 7000 изображений...\n",
      "Скопировано 8000 изображений...\n",
      "Скопировано 9000 изображений...\n",
      "Скопировано 10000 изображений...\n",
      "Скопировано 11000 изображений...\n",
      "Скопировано 12000 изображений...\n",
      "Скопировано 13000 изображений...\n",
      "Скопировано 14000 изображений...\n",
      "Скопировано 15000 изображений...\n",
      "Скопировано 16000 изображений...\n",
      "Скопировано 17000 изображений...\n",
      "Копирование изображений из generated_data/sah_filtered завершено.\n"
     ]
    }
   ],
   "source": [
    "prepare_split(train_src_folder, train_labels_file, train_target_images, train_target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4159dd0a-c6d8-41d0-8096-44281fbbba37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подготовка валидационного набора...\n",
      "Файл меток сохранён: data/sah/val/labels/labels.csv\n",
      "Скопировано 1000 изображений...\n",
      "Скопировано 2000 изображений...\n",
      "Скопировано 3000 изображений...\n",
      "Скопировано 4000 изображений...\n",
      "Копирование изображений из generated_data/val завершено.\n"
     ]
    }
   ],
   "source": [
    "print(\"Подготовка валидационного набора...\")\n",
    "prepare_split(val_src_folder, val_labels_file, val_target_images, val_target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a60d9095-16e5-4186-8f1f-95de8f4fa230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/deep-text-recognition-benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/workspace/deep-text-recognition-benchmark'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd deep-text-recognition-benchmark\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cc5ca92-e7a9-4049-9e7c-0c864e491a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lmdb in /opt/conda/lib/python3.10/site-packages (1.5.1)\n",
      "Collecting fire\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m272.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting termcolor (from fire)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114247 sha256=ca2b3e5662087b343a5a71e379d981be34687b1aa2071f6ae9d879e7ee49a52c\n",
      "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
      "Successfully built fire\n",
      "Installing collected packages: termcolor, fire\n",
      "Successfully installed fire-0.7.0 termcolor-2.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install lmdb fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b56f3d93-ca00-4e49-ab19-6eb16c52d9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Use multi-GPU setting ------\n",
      "if you stuck too long time with multi-GPU setting, try to set --workers 0\n",
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: /workspace/data/sah/train/images\n",
      "opt.select_data: ['MJ', 'ST']\n",
      "opt.batch_ratio: ['0.5', '0.5']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    /workspace/data/sah/train/images\t dataset: MJ\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/deep-text-recognition-benchmark/train.py\", line 317, in <module>\n",
      "    train(opt)\n",
      "  File \"/workspace/deep-text-recognition-benchmark/train.py\", line 31, in train\n",
      "    train_dataset = Batch_Balanced_Dataset(opt)\n",
      "  File \"/workspace/deep-text-recognition-benchmark/dataset.py\", line 42, in __init__\n",
      "    _dataset, _dataset_log = hierarchical_dataset(root=opt.train_data, opt=opt, select_data=[selected_d])\n",
      "  File \"/workspace/deep-text-recognition-benchmark/dataset.py\", line 124, in hierarchical_dataset\n",
      "    concatenated_dataset = ConcatDataset(dataset_list)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 317, in __init__\n",
      "    assert len(self.datasets) > 0, 'datasets should not be an empty iterable'  # type: ignore[arg-type]\n",
      "AssertionError: datasets should not be an empty iterable\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0,1,2,3,4 python3 train.py --train_data /workspace/data/sah/train/images --valid_data /workspace/data/sah/val/images --Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn --batch_size 64 --num_iter 300000 --exp_name sah_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6175a48f-c1fb-42a9-afc5-725f709a12b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspace/deep-text-recognition-benchmark/create_lmdb_dataset.py\", line 87, in <module>\n",
      "    fire.Fire(createDataset)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/fire/core.py\", line 135, in Fire\n",
      "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/fire/core.py\", line 468, in _Fire\n",
      "    component, remaining_args = _CallAndUpdateTrace(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/fire/core.py\", line 684, in _CallAndUpdateTrace\n",
      "    component = fn(*varargs, **kwargs)\n",
      "  File \"/workspace/deep-text-recognition-benchmark/create_lmdb_dataset.py\", line 47, in createDataset\n",
      "    imagePath, label = datalist[i].strip('\\n').split('\\t')\n",
      "ValueError: not enough values to unpack (expected 2, got 1)\n"
     ]
    }
   ],
   "source": [
    "!python3 create_lmdb_dataset.py --inputPath /workspace/data/sah/train/images --gtFile /workspace/data/sah/train/labels/labels.csv --outputPath /workspace/data/sah_lmdb/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d1d9a7d-a48a-4024-a2aa-0442541860eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка исходного файла с метками\n",
    "df = pd.read_csv('/workspace/data/sah/train/labels/labels.csv')\n",
    "df1 = pd.read_csv('/workspace/data/sah/val/labels/labels.csv')\n",
    "\n",
    "# Преобразование в нужный формат (замена запятой на табуляцию)\n",
    "df.to_csv('/workspace/data/sah/train/labels/labels.txt', sep='\\t', index=False, header=False)\n",
    "df1.to_csv('/workspace/data/sah/val/labels/labels.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ead0bea-c299-49c4-b15a-866b26533f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 1000 / 17405\n",
      "Written 2000 / 17405\n",
      "Written 3000 / 17405\n",
      "Written 4000 / 17405\n",
      "Written 5000 / 17405\n",
      "Written 6000 / 17405\n",
      "Written 7000 / 17405\n",
      "Written 8000 / 17405\n",
      "Written 9000 / 17405\n",
      "Written 10000 / 17405\n",
      "Written 11000 / 17405\n",
      "Written 12000 / 17405\n",
      "Written 13000 / 17405\n",
      "Written 14000 / 17405\n",
      "Written 15000 / 17405\n",
      "Written 16000 / 17405\n",
      "Written 17000 / 17405\n",
      "Created dataset with 17405 samples\n"
     ]
    }
   ],
   "source": [
    "!python3 create_lmdb_dataset.py --inputPath /workspace/data/sah/train --gtFile /workspace/data/sah/train/labels/labels.txt --outputPath /workspace/data/sah_lmdb/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da4da257-a1c3-4a60-b835-6977f31dd9e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 1000 / 4352\n",
      "Written 2000 / 4352\n",
      "Written 3000 / 4352\n",
      "Written 4000 / 4352\n",
      "Created dataset with 4352 samples\n"
     ]
    }
   ],
   "source": [
    "!python3 create_lmdb_dataset.py --inputPath /workspace/data/sah/val --gtFile /workspace/data/sah/val/labels/labels.txt --outputPath /workspace/data/sah_lmdb/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "10c36d3c-0c2c-4679-a4ca-1ce18953e4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Use multi-GPU setting ------\n",
      "if you stuck too long time with multi-GPU setting, try to set --workers 0\n",
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: /workspace/data/sah_lmdb/train\n",
      "opt.select_data: ['MJ', 'ST']\n",
      "opt.batch_ratio: ['0.5', '0.5']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    /workspace/data/sah_lmdb/train\t dataset: MJ\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/deep-text-recognition-benchmark/train.py\", line 317, in <module>\n",
      "    train(opt)\n",
      "  File \"/workspace/deep-text-recognition-benchmark/train.py\", line 31, in train\n",
      "    train_dataset = Batch_Balanced_Dataset(opt)\n",
      "  File \"/workspace/deep-text-recognition-benchmark/dataset.py\", line 42, in __init__\n",
      "    _dataset, _dataset_log = hierarchical_dataset(root=opt.train_data, opt=opt, select_data=[selected_d])\n",
      "  File \"/workspace/deep-text-recognition-benchmark/dataset.py\", line 124, in hierarchical_dataset\n",
      "    concatenated_dataset = ConcatDataset(dataset_list)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 317, in __init__\n",
      "    assert len(self.datasets) > 0, 'datasets should not be an empty iterable'  # type: ignore[arg-type]\n",
      "AssertionError: datasets should not be an empty iterable\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0,1,2,3 python3 train.py \\\n",
    "--train_data /workspace/data/sah_lmdb/train \\\n",
    "--valid_data /workspace/data/sah_lmdb/val \\\n",
    "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \\\n",
    "--batch_size 64 --num_iter 300000 --exp_name sah_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca6b6372-71ab-4748-b4b9-1aa54636cf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.mdb  lock.mdb\n"
     ]
    }
   ],
   "source": [
    "!ls /workspace/data/sah_lmdb/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e7510a9-2175-46b2-87d7-b3dbd2f2dba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Use multi-GPU setting ------\n",
      "if you stuck too long time with multi-GPU setting, try to set --workers 0\n",
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: data/sah_lmdb/train\n",
      "opt.select_data: ['default']\n",
      "opt.batch_ratio: ['1']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    data/sah_lmdb/train\t dataset: default\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/deep-text-recognition-benchmark/train.py\", line 317, in <module>\n",
      "    train(opt)\n",
      "  File \"/workspace/deep-text-recognition-benchmark/train.py\", line 31, in train\n",
      "    train_dataset = Batch_Balanced_Dataset(opt)\n",
      "  File \"/workspace/deep-text-recognition-benchmark/dataset.py\", line 42, in __init__\n",
      "    _dataset, _dataset_log = hierarchical_dataset(root=opt.train_data, opt=opt, select_data=[selected_d])\n",
      "  File \"/workspace/deep-text-recognition-benchmark/dataset.py\", line 124, in hierarchical_dataset\n",
      "    concatenated_dataset = ConcatDataset(dataset_list)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 317, in __init__\n",
      "    assert len(self.datasets) > 0, 'datasets should not be an empty iterable'  # type: ignore[arg-type]\n",
      "AssertionError: datasets should not be an empty iterable\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0,1,2,3 python3 deep-text-recognition-benchmark/train.py \\\n",
    "--train_data data/sah_lmdb/train \\\n",
    "--valid_data data/sah_lmdb/val \\\n",
    "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \\\n",
    "--batch_size 64 --num_iter 300000 --exp_name sah_experiment \\\n",
    "--select_data 'default' --batch_ratio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4a87ab0d-66d1-437c-b702-e50de232d585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1eaa6e1a-532a-4a00-a45e-e2dabed497c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.mdb  lock.mdb\n",
      "data.mdb  lock.mdb\n"
     ]
    }
   ],
   "source": [
    "!ls data/sah_lmdb/train\n",
    "!ls data/sah_lmdb/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bbfadaf7-70d9-4dcd-9ab8-b8c2ece5e2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Use multi-GPU setting ------\n",
      "if you stuck too long time with multi-GPU setting, try to set --workers 0\n",
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: data/sah_lmdb/train\n",
      "opt.select_data: ['MJ', 'ST']\n",
      "opt.batch_ratio: ['0.5', '0.5']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    data/sah_lmdb/train\t dataset: MJ\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/deep-text-recognition-benchmark/train.py\", line 317, in <module>\n",
      "    train(opt)\n",
      "  File \"/workspace/deep-text-recognition-benchmark/train.py\", line 31, in train\n",
      "    train_dataset = Batch_Balanced_Dataset(opt)\n",
      "  File \"/workspace/deep-text-recognition-benchmark/dataset.py\", line 42, in __init__\n",
      "    _dataset, _dataset_log = hierarchical_dataset(root=opt.train_data, opt=opt, select_data=[selected_d])\n",
      "  File \"/workspace/deep-text-recognition-benchmark/dataset.py\", line 124, in hierarchical_dataset\n",
      "    concatenated_dataset = ConcatDataset(dataset_list)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 317, in __init__\n",
      "    assert len(self.datasets) > 0, 'datasets should not be an empty iterable'  # type: ignore[arg-type]\n",
      "AssertionError: datasets should not be an empty iterable\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0,1,2,3 python3 deep-text-recognition-benchmark/train.py \\\n",
    "--train_data data/sah_lmdb/train \\\n",
    "--valid_data data/sah_lmdb/val \\\n",
    "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \\\n",
    "--batch_size 64 --num_iter 300000 --exp_name sah_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d17a82-fe8e-4fc5-a221-e72f0b9a96a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
