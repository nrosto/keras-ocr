{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: utils in /opt/conda/lib/python3.10/site-packages (1.0.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: natsort in /opt/conda/lib/python3.10/site-packages (8.4.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.18.5)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.28.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.17.0)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.10/site-packages (from wandb) (4.9.0)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.67.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorboard) (23.1)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.67.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: werkzeug, tensorboard-data-server, markdown, grpcio, absl-py, tensorboard\n",
      "Successfully installed absl-py-2.1.0 grpcio-1.67.0 markdown-3.7 tensorboard-2.18.0 tensorboard-data-server-0.7.2 werkzeug-3.0.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install utils pandas natsort nltk wandb tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:23.488642Z",
     "start_time": "2021-07-23T04:19:21.854534Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import yaml\n",
    "from train import train\n",
    "from utils import AttrDict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:23.885144Z",
     "start_time": "2021-07-23T04:19:23.880564Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "def clean_text(text):\n",
    "    # Нормализация до NFC\n",
    "    text = unicodedata.normalize('NFC', text)\n",
    "    \n",
    "    # Удаление всех контролирующих символов (категория C*)\n",
    "    text = ''.join(c for c in text if not unicodedata.category(c).startswith('C'))\n",
    "    \n",
    "    # Разрешённые комбинирующие символы\n",
    "    allowed_combining = {'\\u0301'}  # Только острый акцент\n",
    "    text = ''.join(c for c in text if not unicodedata.combining(c) or c in allowed_combining)\n",
    "    \n",
    "    # Явное удаление специфических нежелательных символов\n",
    "    text = text.replace('\\u200e', '').replace('\\u200f', '')  # Удаление LRM и RLM\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf8\") as stream:\n",
    "        opt = yaml.safe_load(stream)\n",
    "    opt = AttrDict(opt)\n",
    "    \n",
    "    if opt.lang_char == 'None':\n",
    "        characters = ''\n",
    "        total_samples_before = 0\n",
    "        total_samples_after = 0\n",
    "        for data in opt['select_data'].split('-'):\n",
    "            csv_path = os.path.join(opt['train_data'], data, 'labels.csv')\n",
    "            df = pd.read_csv(csv_path, sep=',', engine='python', usecols=['filename', 'words'], keep_default_na=False)\n",
    "            print(f\"Прочитано {len(df)} примеров из {csv_path}\")\n",
    "            df['words'] = df['words'].apply(clean_text)\n",
    "            print(f\"Пример до очистки: {df['words'].iloc[0]}\")\n",
    "            # Удаление примеров с пустыми метками после очистки\n",
    "            df = df[df['words'].str.strip() != '']\n",
    "            print(f\"Оставлено {len(df)} примеров после очистки из {csv_path}\")\n",
    "            total_samples_before += len(df)\n",
    "            all_char = ''.join(df['words'])\n",
    "            characters += ''.join(set(all_char))\n",
    "        characters = sorted(set(characters))\n",
    "        opt.character = ''.join(characters)\n",
    "    else:\n",
    "        opt.character = opt.number + opt.symbol + opt.lang_char\n",
    "    \n",
    "    print(f\"Общее количество символов в opt.character: {len(opt.character)}\")\n",
    "    \n",
    "    # Дополнительная проверка на наличие неподдерживаемых символов\n",
    "    unsupported_chars = set()\n",
    "    for data in opt['select_data'].split('-'):\n",
    "        csv_path = os.path.join(opt['train_data'], data, 'labels.csv')\n",
    "        df = pd.read_csv(csv_path, sep=',', engine='python', usecols=['filename', 'words'], keep_default_na=False)\n",
    "        df['words'] = df['words'].apply(clean_text)\n",
    "        for word in df['words']:\n",
    "            for char in word:\n",
    "                if char not in opt.character:\n",
    "                    unsupported_chars.add(char)\n",
    "    if unsupported_chars:\n",
    "        print(f\"Найдено неподдерживаемых символов: {unsupported_chars}\")\n",
    "    else:\n",
    "        print(\"Неподдерживаемых символов не найдено.\")\n",
    "    \n",
    "    os.makedirs(f'./saved_models/{opt.experiment_name}', exist_ok=True)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_wandb(opt):\n",
    "    wandb.init(\n",
    "        project=\"EasyOCR_Yakut\",  # Название проекта в wandb\n",
    "        config=opt,               # Передаём конфигурацию как гиперпараметры\n",
    "        name=opt.experiment_name, # Название запуска\n",
    "        sync_tensorboard=True     # Если используете TensorBoard\n",
    "    )\n",
    "    # Логирование дополнительных параметров при необходимости\n",
    "    wandb.config.update(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:49:07.045060Z",
     "start_time": "2021-07-23T04:20:15.050992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общее количество символов в opt.character: 57\n",
      "Неподдерживаемых символов не найдено.\n",
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: all_data/\n",
      "opt.select_data: ['sah_filtered']\n",
      "opt.batch_ratio: ['1']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    all_data/\t dataset: sah_filtered\n",
      "all_data//sah_filtered\n",
      "sub-directory:\t/sah_filtered\t num samples: 31983\n",
      "num total samples of sah_filtered: 31983 x 1.0 (total_data_usage_ratio) = 31983\n",
      "num samples of sah_filtered per batch: 64 x 1.0 (batch_ratio) = 64\n",
      "--------------------------------------------------------------------------------\n",
      "Total_batch_size: 64 = 64\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    all_data/val\t dataset: /\n",
      "all_data/val/\n",
      "sub-directory:\t/.\t num samples: 7463\n",
      "--------------------------------------------------------------------------------\n",
      "No Transformation module specified\n",
      "model input parameters 32 1600 20 1 256 256 58 100 None VGG BiLSTM CTC\n",
      "Model:\n",
      "DataParallel(\n",
      "  (module): Model(\n",
      "    (FeatureExtraction): VGG_FeatureExtractor(\n",
      "      (ConvNet): Sequential(\n",
      "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (7): ReLU(inplace=True)\n",
      "        (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (9): ReLU(inplace=True)\n",
      "        (10): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "        (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (13): ReLU(inplace=True)\n",
      "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (16): ReLU(inplace=True)\n",
      "        (17): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "        (18): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "        (19): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
      "    (SequenceModeling): Sequential(\n",
      "      (0): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (Prediction): Linear(in_features=256, out_features=58, bias=True)\n",
      "  )\n",
      ")\n",
      "Modules, Parameters\n",
      "module.FeatureExtraction.ConvNet.0.weight 288\n",
      "module.FeatureExtraction.ConvNet.0.bias 32\n",
      "module.FeatureExtraction.ConvNet.3.weight 18432\n",
      "module.FeatureExtraction.ConvNet.3.bias 64\n",
      "module.FeatureExtraction.ConvNet.6.weight 73728\n",
      "module.FeatureExtraction.ConvNet.6.bias 128\n",
      "module.FeatureExtraction.ConvNet.8.weight 147456\n",
      "module.FeatureExtraction.ConvNet.8.bias 128\n",
      "module.FeatureExtraction.ConvNet.11.weight 294912\n",
      "module.FeatureExtraction.ConvNet.12.weight 256\n",
      "module.FeatureExtraction.ConvNet.12.bias 256\n",
      "module.FeatureExtraction.ConvNet.14.weight 589824\n",
      "module.FeatureExtraction.ConvNet.15.weight 256\n",
      "module.FeatureExtraction.ConvNet.15.bias 256\n",
      "module.FeatureExtraction.ConvNet.18.weight 262144\n",
      "module.FeatureExtraction.ConvNet.18.bias 256\n",
      "module.SequenceModeling.0.rnn.weight_ih_l0 262144\n",
      "module.SequenceModeling.0.rnn.weight_hh_l0 262144\n",
      "module.SequenceModeling.0.rnn.bias_ih_l0 1024\n",
      "module.SequenceModeling.0.rnn.bias_hh_l0 1024\n",
      "module.SequenceModeling.0.rnn.weight_ih_l0_reverse 262144\n",
      "module.SequenceModeling.0.rnn.weight_hh_l0_reverse 262144\n",
      "module.SequenceModeling.0.rnn.bias_ih_l0_reverse 1024\n",
      "module.SequenceModeling.0.rnn.bias_hh_l0_reverse 1024\n",
      "module.SequenceModeling.0.linear.weight 131072\n",
      "module.SequenceModeling.0.linear.bias 256\n",
      "module.SequenceModeling.1.rnn.weight_ih_l0 262144\n",
      "module.SequenceModeling.1.rnn.weight_hh_l0 262144\n",
      "module.SequenceModeling.1.rnn.bias_ih_l0 1024\n",
      "module.SequenceModeling.1.rnn.bias_hh_l0 1024\n",
      "module.SequenceModeling.1.rnn.weight_ih_l0_reverse 262144\n",
      "module.SequenceModeling.1.rnn.weight_hh_l0_reverse 262144\n",
      "module.SequenceModeling.1.rnn.bias_ih_l0_reverse 1024\n",
      "module.SequenceModeling.1.rnn.bias_hh_l0_reverse 1024\n",
      "module.SequenceModeling.1.linear.weight 131072\n",
      "module.SequenceModeling.1.linear.bias 256\n",
      "module.Prediction.weight 14848\n",
      "module.Prediction.bias 58\n",
      "Total Trainable Params: 3771322\n",
      "Trainable params num :  3771322\n",
      "Optimizer:\n",
      "Adadelta (\n",
      "Parameter Group 0\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 1.0\n",
      "    maximize: False\n",
      "    rho: 0.95\n",
      "    weight_decay: 0\n",
      ")\n",
      "------------ Options -------------\n",
      "number: 0123456789\n",
      "symbol: .,:;?!\\- \n",
      "lang_char: абвгдежзийклмнопрстуфхцчшщъыьэюяёҕҥүһө\n",
      "experiment_name: sah_filtered\n",
      "train_data: all_data/\n",
      "valid_data: all_data/val\n",
      "manualSeed: 1111\n",
      "workers: 8\n",
      "batch_size: 64\n",
      "num_iter: 4000\n",
      "valInterval: 200\n",
      "saved_model: \n",
      "FT: False\n",
      "optim: False\n",
      "lr: 1.0\n",
      "beta1: 0.9\n",
      "rho: 0.95\n",
      "eps: 1e-08\n",
      "grad_clip: 5\n",
      "select_data: ['sah_filtered']\n",
      "batch_ratio: ['1']\n",
      "total_data_usage_ratio: 1.0\n",
      "batch_max_length: 100\n",
      "imgH: 32\n",
      "imgW: 1600\n",
      "rgb: False\n",
      "contrast_adjust: 0.0\n",
      "sensitive: True\n",
      "PAD: True\n",
      "data_filtering_off: False\n",
      "Transformation: None\n",
      "FeatureExtraction: VGG\n",
      "SequenceModeling: BiLSTM\n",
      "Prediction: CTC\n",
      "num_fiducial: 20\n",
      "input_channel: 1\n",
      "output_channel: 256\n",
      "hidden_size: 256\n",
      "decode: greedy\n",
      "new_prediction: False\n",
      "freeze_FeatureFxtraction: False\n",
      "freeze_SequenceModeling: False\n",
      "character: 0123456789.,:;?!\\- абвгдежзийклмнопрстуфхцчшщъыьэюяёҕҥүһө\n",
      "num_class: 58\n",
      "---------------------------------------\n",
      "\n",
      "training time:  59.46608519554138\n",
      "[200/4000] Train loss: 3.81403, Valid loss: 2.81989, Elapsed_time: 59.46643\n",
      "Current_accuracy : 0.054, Current_norm_ED  : 0.1108\n",
      "Best_accuracy    : 0.054, Best_norm_ED     : 0.1108\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "хаартыскаҕа: курбуһахтааҕы оҕо саадын тутуута |     .                     | 0.0000\tFalse\n",
      "уонна норуот тыыннаах хаалар эбэтэр өлөр-тиллэр дьалхааннаах кэмигэр |      р р                  | 0.0000\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  105.36226153373718\n",
      "training time:  59.60301375389099\n",
      "[400/4000] Train loss: 1.23871, Valid loss: 0.32733, Elapsed_time: 224.43201\n",
      "Current_accuracy : 10.036, Current_norm_ED  : 0.9233\n",
      "Best_accuracy    : 10.036, Best_norm_ED     : 0.9233\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "бүттүбүт.                 | бүтүбүт.                  | 0.2095\tFalse\n",
      "үтүөлээх николай тарскай аатын үйэтитэргэ үлэ бөҕөнү ыыппыппыт | үтүөлээх николай тарскай аатын үйэтитэргэ үлэ бөҕөнү ыыттытыт. | 0.0000\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  149.1205005645752\n",
      "training time:  60.46001672744751\n"
     ]
    }
   ],
   "source": [
    "opt = get_config(\"config_files/sah_filtered_config.yaml\")\n",
    "train(opt, amp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
